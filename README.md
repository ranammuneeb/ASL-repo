
## ğŸ“‚ Folder Structure

```
project/
â”œâ”€â”€ app.py                    # Main Flask backend
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ asl_model.joblib      # ML model (auto-downloaded)
â”‚   â””â”€â”€ label_encoder.joblib  # Label encoder (auto-downloaded)
â”œâ”€â”€ static/
â”‚   â””â”€â”€ audio/                # Contains generated .mp3 files
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html            # Frontend web page
```

---

## ğŸ§  How It Works

1. OpenCV captures video from the webcam.
2. MediaPipe extracts 21 hand landmarks (x, y, z = 63 features).
3. The trained RandomForestClassifier model predicts the ASL letter.
4. A letter is only added to the sentence if:
   - It's stable across multiple frames, and
   - The model's confidence is **85% or more**.
5. User can press:
   - âœ… **Speak** â†’ converts the sentence to an audio file
   - âŒ **Clear** â†’ resets the current sentence
6. Audio is saved and streamed via browser.

---


